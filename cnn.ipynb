{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Convolutional Neural Networks**"
      ],
      "metadata": {
        "id": "ZPFlNFxhWS4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep data specifically for a CNN\n",
        "Create a more sophisticated CNN model, understanding a greater variety of model layers\n",
        "Train a CNN model and observe its performance.\n",
        "Build and trained a simple model to classify ASL images."
      ],
      "metadata": {
        "id": "xGUs5y4pXBak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGuYXGmmTnk8",
        "outputId": "35a31787-9920-4ea5-d0c1-e17452e20ce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "Am6V4NCnWvx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"data/sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"data/sign_mnist_valid.csv\")"
      ],
      "metadata": {
        "id": "5P4lqRGUTzIv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = train_df.head().copy()  # see the top 5 rows\n",
        "sample_df.pop('label')\n",
        "sample_x = sample_df.values\n",
        "sample_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tORb3UCiT9ND",
        "outputId": "7ec2a87d-921f-4505-a14d-d3e94ec8dd24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[107, 118, 127, ..., 204, 203, 202],\n",
              "       [155, 157, 156, ..., 103, 135, 149],\n",
              "       [187, 188, 188, ..., 195, 194, 195],\n",
              "       [211, 211, 212, ..., 222, 229, 163],\n",
              "       [164, 167, 170, ..., 163, 164, 179]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81nLAP0TUA-u",
        "outputId": "6d2007a9-5209-4804-9550-21fa4a5eb953"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 28\n",
        "IMG_WIDTH = 28\n",
        "IMG_CHS = 1\n",
        "\n",
        "sample_x = sample_x.reshape(-1, IMG_CHS, IMG_HEIGHT, IMG_WIDTH)\n",
        "sample_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIiP_PvoUG9P",
        "outputId": "a5e6b155-7df8-478f-cb7b-c5917ce17245"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, base_df):\n",
        "        x_df = base_df.copy()\n",
        "        y_df = x_df.pop('label')\n",
        "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
        "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
        "        self.xs = torch.tensor(x_df).float().to(device)\n",
        "        self.ys = torch.tensor(y_df).to(device)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.xs[idx]\n",
        "        y = self.ys[idx]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)"
      ],
      "metadata": {
        "id": "y76juGn2ULxW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating data loader"
      ],
      "metadata": {
        "id": "iCVX9HGvXTf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data = MyDataset(train_df)\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_N = len(train_loader.dataset)\n",
        "\n",
        "valid_data = MyDataset(valid_df)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
        "valid_N = len(valid_loader.dataset)"
      ],
      "metadata": {
        "id": "NQt3Nm_JURcl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGdt2MMoUV8D",
        "outputId": "12b9719b-554e-4ded-d720-f014548b049f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[0.4784, 0.5020, 0.5216,  ..., 0.6353, 0.6314, 0.6314],\n",
              "           [0.4941, 0.5137, 0.5294,  ..., 0.6471, 0.6471, 0.6471],\n",
              "           [0.5098, 0.5255, 0.5451,  ..., 0.6627, 0.6588, 0.6588],\n",
              "           ...,\n",
              "           [0.6706, 0.6824, 0.7020,  ..., 0.8471, 0.8431, 0.8392],\n",
              "           [0.6706, 0.6902, 0.7059,  ..., 0.8510, 0.8510, 0.8471],\n",
              "           [0.6706, 0.6863, 0.7059,  ..., 0.8549, 0.8510, 0.8510]]],\n",
              " \n",
              " \n",
              "         [[[0.4431, 0.4667, 0.4863,  ..., 0.7529, 0.7490, 0.7490],\n",
              "           [0.4471, 0.4627, 0.4902,  ..., 0.7529, 0.7529, 0.7529],\n",
              "           [0.4510, 0.4627, 0.4980,  ..., 0.7569, 0.7608, 0.7608],\n",
              "           ...,\n",
              "           [0.5098, 0.5294, 0.5765,  ..., 0.8980, 0.9020, 0.9020],\n",
              "           [0.5098, 0.5373, 0.5804,  ..., 0.9098, 0.9059, 0.9059],\n",
              "           [0.5020, 0.5333, 0.5843,  ..., 0.9098, 0.9098, 0.9098]]],\n",
              " \n",
              " \n",
              "         [[[0.7098, 0.7216, 0.7294,  ..., 0.7529, 0.7490, 0.7490],\n",
              "           [0.7216, 0.7412, 0.7529,  ..., 0.7725, 0.7647, 0.7608],\n",
              "           [0.7255, 0.7451, 0.7569,  ..., 0.7882, 0.7765, 0.7725],\n",
              "           ...,\n",
              "           [0.8980, 0.9216, 0.9294,  ..., 0.9882, 1.0000, 0.7961],\n",
              "           [0.9059, 0.9294, 0.9373,  ..., 1.0000, 0.7451, 0.4235],\n",
              "           [0.9020, 0.9216, 0.9373,  ..., 0.6000, 0.4157, 0.3529]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0.8392, 0.8431, 0.8510,  ..., 0.8549, 0.8471, 0.8431],\n",
              "           [0.8510, 0.8471, 0.8549,  ..., 0.8588, 0.8471, 0.8549],\n",
              "           [0.8549, 0.8549, 0.8667,  ..., 0.8784, 0.8667, 0.8706],\n",
              "           ...,\n",
              "           [0.9804, 0.9843, 0.9882,  ..., 1.0000, 1.0000, 1.0000],\n",
              "           [0.9765, 0.9765, 0.9804,  ..., 1.0000, 1.0000, 1.0000],\n",
              "           [0.9804, 0.9843, 0.9882,  ..., 1.0000, 1.0000, 1.0000]]],\n",
              " \n",
              " \n",
              "         [[[0.4667, 0.4706, 0.4824,  ..., 0.5569, 0.5569, 0.5569],\n",
              "           [0.4706, 0.4745, 0.4902,  ..., 0.5647, 0.5608, 0.5608],\n",
              "           [0.4745, 0.4824, 0.4902,  ..., 0.5686, 0.5686, 0.5647],\n",
              "           ...,\n",
              "           [0.5412, 0.5490, 0.5569,  ..., 0.6314, 0.6314, 0.6353],\n",
              "           [0.5451, 0.5529, 0.5608,  ..., 0.6353, 0.6353, 0.6392],\n",
              "           [0.5412, 0.5529, 0.5608,  ..., 0.6353, 0.6353, 0.6392]]],\n",
              " \n",
              " \n",
              "         [[[0.1294, 0.1804, 0.2431,  ..., 0.4627, 0.4667, 0.4706],\n",
              "           [0.1255, 0.2235, 0.2314,  ..., 0.4667, 0.4706, 0.4745],\n",
              "           [0.1255, 0.2549, 0.2118,  ..., 0.4667, 0.4745, 0.4784],\n",
              "           ...,\n",
              "           [0.0039, 0.0902, 0.2039,  ..., 0.5686, 0.5765, 0.5765],\n",
              "           [0.0000, 0.1059, 0.2039,  ..., 0.5725, 0.5765, 0.5765],\n",
              "           [0.0000, 0.1255, 0.2039,  ..., 0.5725, 0.5765, 0.5765]]]]),\n",
              " tensor([19,  5, 21, 16, 16, 23, 23,  9, 20,  6, 10,  5, 11, 10, 23,  2,  3, 21,\n",
              "         18,  4, 10,  0,  1, 16, 11, 10,  3, 22, 15,  4, 11, 21])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kizO1oiNUbfN",
        "outputId": "ec98d1cc-7f1e-4712-9201-ba0305d7e937"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZe7SgLnUcL6",
        "outputId": "89a4cbf1-d3a5-43b2-b49e-879d9a4e3680"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a Convolutional Model\n",
        "using batch normalization, maxpool2d, dropout, flattening the output."
      ],
      "metadata": {
        "id": "ZMF1cj9gXdXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 24\n",
        "kernel_size = 3\n",
        "flattened_img_size = 75 * 3 * 3\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # First convolution\n",
        "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 28 x 28\n",
        "    nn.BatchNorm2d(25),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),  # 25 x 14 x 14\n",
        "    # Second convolution\n",
        "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 14 x 14\n",
        "    nn.BatchNorm2d(50),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(.2),\n",
        "    nn.MaxPool2d(2, stride=2),  # 50 x 7 x 7\n",
        "    # Third convolution\n",
        "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 7 x 7\n",
        "    nn.BatchNorm2d(75),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),  # 75 x 3 x 3\n",
        "    # Flatten to Dense\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(flattened_img_size, 512),\n",
        "    nn.Dropout(.3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, n_classes)\n",
        ")"
      ],
      "metadata": {
        "id": "wMnzKcFiUhJL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.compile(model.to(device))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB5bCO8LUtpk",
        "outputId": "4c99fb69-bd33-488c-a274-7ba774c784ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): Sequential(\n",
              "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(50, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU()\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (13): Flatten(start_dim=1, end_dim=-1)\n",
              "    (14): Linear(in_features=675, out_features=512, bias=True)\n",
              "    (15): Dropout(p=0.3, inplace=False)\n",
              "    (16): ReLU()\n",
              "    (17): Linear(in_features=512, out_features=24, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters())"
      ],
      "metadata": {
        "id": "ywXXa-umUwrE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_accuracy(output, y, N):\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
        "    return correct / N"
      ],
      "metadata": {
        "id": "XSxxBA_HU0DQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model"
      ],
      "metadata": {
        "id": "rx1rjqiUXl_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in valid_loader:\n",
        "            output = model(x)\n",
        "\n",
        "            loss += loss_function(output, y).item()\n",
        "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
        "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ],
      "metadata": {
        "id": "A22PRVsdU0w3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        output = model(x)\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = loss_function(output, y)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss += batch_loss.item()\n",
        "        accuracy += get_batch_accuracy(output, y, train_N)\n",
        "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ],
      "metadata": {
        "id": "FhBnROIAU6th"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    train()\n",
        "    validate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pml0QfLHU_bF",
        "outputId": "e0a38bb3-cadc-49bf-cc0f-c102cd1d3adb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train - Loss: 1.2221 Accuracy: 0.9996\n",
            "Valid - Loss: 40.2904 Accuracy: 0.9525\n",
            "Epoch: 1\n",
            "Train - Loss: 10.6527 Accuracy: 0.9966\n",
            "Valid - Loss: 19.9260 Accuracy: 0.9785\n",
            "Epoch: 2\n",
            "Train - Loss: 1.4870 Accuracy: 0.9995\n",
            "Valid - Loss: 211.2135 Accuracy: 0.8279\n",
            "Epoch: 3\n",
            "Train - Loss: 4.4204 Accuracy: 0.9985\n",
            "Valid - Loss: 16.7932 Accuracy: 0.9788\n",
            "Epoch: 4\n",
            "Train - Loss: 2.8317 Accuracy: 0.9992\n",
            "Valid - Loss: 57.5201 Accuracy: 0.9459\n",
            "Epoch: 5\n",
            "Train - Loss: 3.3487 Accuracy: 0.9989\n",
            "Valid - Loss: 14.5140 Accuracy: 0.9749\n",
            "Epoch: 6\n",
            "Train - Loss: 5.1286 Accuracy: 0.9984\n",
            "Valid - Loss: 28.8117 Accuracy: 0.9700\n",
            "Epoch: 7\n",
            "Train - Loss: 3.8070 Accuracy: 0.9987\n",
            "Valid - Loss: 33.9592 Accuracy: 0.9734\n",
            "Epoch: 8\n",
            "Train - Loss: 2.0382 Accuracy: 0.9995\n",
            "Valid - Loss: 14.9603 Accuracy: 0.9802\n",
            "Epoch: 9\n",
            "Train - Loss: 3.5345 Accuracy: 0.9990\n",
            "Valid - Loss: 36.4293 Accuracy: 0.9716\n"
          ]
        }
      ]
    }
  ]
}